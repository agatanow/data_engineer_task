{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audition tasks for Data Engineer\n",
    "<br>\n",
    "\n",
    "### Import used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Load received files: test.csv, test_level.csv, class.csv\n",
    "### Task 2\n",
    "Check if files are correct according to data in columns etc. If not please delete these rows.\n",
    "Will be in the plus if you do this as a simple script - not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator(object):\n",
    "    @staticmethod\n",
    "    def int_validator(x, name, show_incorrect, not_null=True):\n",
    "        try:\n",
    "            if not_null or x[name] != '':\n",
    "                x[name] = int(x[name]) \n",
    "        except ValueError:\n",
    "            if show_incorrect:\n",
    "                print('Test field \"{}\" has incorrect format {} (expected int)'.format(name,x[name]))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def float_validator(x, name, show_incorrect, not_null=True):\n",
    "        try:\n",
    "            if not_null or x[name] != '':\n",
    "                x[name] = float(x[name]) \n",
    "        except ValueError:\n",
    "            if show_incorrect:\n",
    "                print('Test field \"{}\" has incorrect format {} (expected float)'.format(name,x[name]))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def date_validator(x, name, date_format, show_incorrect, not_null=True):\n",
    "        try:\n",
    "            if not_null or x[name] != '':\n",
    "                x[name] = datetime.strptime(x[name], date_format) \n",
    "        except ValueError:\n",
    "            if show_incorrect:\n",
    "                print('Test field \"{}\" has incorrect format {} (expected date format: {})'.format(name,x[name], date_format))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def isodate_validator(x, name, show_incorrect, not_null=True):\n",
    "        try:\n",
    "            if not_null or x[name] != '':\n",
    "                x[name] = dateutil.parser.parse(x[name])\n",
    "        except ValueError:\n",
    "            if show_incorrect:\n",
    "                print('Test field \"{}\" has incorrect format {} (expected isodate format)'.format(name,x[name], date_format))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_test(row, show_incorrect=False):\n",
    "        return ( Validator.int_validator(row, 'id', show_incorrect) and\n",
    "            Validator.int_validator(row, 'student_id', show_incorrect) and\n",
    "            Validator.int_validator(row, 'class_id', show_incorrect) and\n",
    "            Validator.date_validator(row, 'created_at', '%d.%m.%y %H:%M', show_incorrect) and\n",
    "            Validator.date_validator(row, 'updated_at', '%d.%m.%y %H:%M', show_incorrect, not_null=False) and\n",
    "            Validator.isodate_validator(row, 'last_event_time', show_incorrect, not_null=False) and\n",
    "            Validator.float_validator(row, 'overall_score', show_incorrect, not_null=False) and\n",
    "            Validator.date_validator(row, 'authorized_at', '%d.%m.%y %H:%M', show_incorrect,not_null=False) and\n",
    "            Validator.float_validator(row, 'speaking_score', show_incorrect, not_null=False) and\n",
    "            Validator.float_validator(row, 'writing_score', show_incorrect, not_null=False) and\n",
    "            Validator.float_validator(row, 'reading_score', show_incorrect, not_null=False) and\n",
    "            Validator.float_validator(row, 'listening_score', show_incorrect, not_null=False) and\n",
    "            Validator.int_validator(row, 'test_level_id', show_incorrect))\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_class(row, show_incorrect=False):\n",
    "        return ( Validator.int_validator(row, 'id', show_incorrect) and\n",
    "            Validator.int_validator(row, 'institution_id', show_incorrect, not_null=False) and\n",
    "            Validator.date_validator(row, 'created_at', '%d.%m.%y %H:%M', show_incorrect) and\n",
    "            Validator.date_validator(row, 'updated_at', '%d.%m.%y %H:%M', show_incorrect, not_null=False))\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_test_level(row, show_incorrect=False):\n",
    "        return ( Validator.int_validator(row, 'id', show_incorrect) and\n",
    "            Validator.date_validator(row, 'created_at', '%d.%m.%y %H:%M', show_incorrect) and\n",
    "            Validator.date_validator(row, 'updated_at', '%d.%m.%y %H:%M', show_incorrect, not_null=False))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, f_validate, key_name='id', show_incorrect=False):\n",
    "    with open(file_path) as csvfile:\n",
    "        reader = csv.DictReader(csvfile, delimiter=';')\n",
    "        return {row[key_name]: row for row in reader if f_validate(row, show_incorrect)}\n",
    "    \n",
    "tests = load_data('input_data/test.csv', Validator.validate_test)\n",
    "classes = load_data('input_data/class.csv', Validator.validate_class)\n",
    "test_levels = load_data('input_data/test_level.csv', Validator.validate_test_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Create first final dataset which will contain information about frequency of tests utilization by\n",
    "classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_utilization(tests, classes, test_levels):\n",
    "    \"\"\"Return test utilization dataset\n",
    "\n",
    "    Keyword arguments:\n",
    "    tests -- tests dataset\n",
    "    classes -- classes dataset\n",
    "    test_levels -- test_levels dataset\n",
    "    show_all_classes -- if true the output dataset will contain all classes, even those that have\n",
    "        no relation with authorized testor or any test in general.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    class_counter = {}\n",
    "    for test_id,test in tests.items():\n",
    "        test_class = classes[test['class_id']]\n",
    "        test_level = test_levels[test['test_level_id']]\n",
    "\n",
    "        if test['authorized_at'] != '':\n",
    "            #enumerate each solved test\n",
    "            if test_class['id'] not in class_counter:\n",
    "                class_counter[test_class['id']] = 0\n",
    "            class_counter[test_class['id']] += 1\n",
    "\n",
    "            #add test to output dataset\n",
    "            res[test_id] = {\n",
    "                'class_id': test_class['id'], \n",
    "                'class_name': test_class['name'],\n",
    "                'teaching_hours': test_class['teaching_hours'],\n",
    "                'test_id': test_id,\n",
    "                'test_level': test_level['name'],\n",
    "                'test_created_at': test['created_at'],\n",
    "                'test_authorized_at': test['authorized_at'],\n",
    "                'class_test_number': class_counter[test_class['id']]\n",
    "            } \n",
    "    return res\n",
    "\n",
    "tests_ut = get_test_utilization(tests, classes, test_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Create a second final dataset which will contain information about average overall scores for\n",
    "tests in classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_filter(org_dic, *list_el):\n",
    "    \"\"\"Return dictonary like org_dic with removed elements from list_el\"\"\"\n",
    "    dic = dict(org_dic)\n",
    "    for x in list_el:\n",
    "        dic.pop(x)\n",
    "    return dic\n",
    "        \n",
    "\n",
    "def get_test_average(tests_ut, tests, classes, show_all_classes = False):\n",
    "    \"\"\"Return test average overall scores dataset\n",
    "\n",
    "    Keyword arguments:\n",
    "    tests_ut -- test utilization dataset\n",
    "    tests -- tests dataset\n",
    "    classes -- classes dataset\n",
    "    show_all_classes -- if true the output dataset will contain all classes, even those that have\n",
    "        no relation with authorized test or any test in general.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    class_counter = {}\n",
    "\n",
    "    for test_id, test_ut in tests_ut.items():\n",
    "        test_status = tests[test_id]['test_status']\n",
    "        test_score = tests[test_id]['overall_score']\n",
    "        new_class = dict_filter(test_ut, 'test_level', 'test_id', 'class_test_number')\n",
    "\n",
    "        #add new class to output dataset\n",
    "        if test_ut['class_id'] not in res:\n",
    "            res[test_ut['class_id']] = new_class\n",
    "\n",
    "        #if test has a score and its status is 'SCORING_SCORED' use it for computing the average score\n",
    "        if test_status == 'SCORING_SCORED' and test_score!='':\n",
    "            if 'avg_class_test_overall_score' in res[test_ut['class_id']]:\n",
    "                res[test_ut['class_id']]['avg_class_test_overall_score'] += float(test_score)\n",
    "                class_counter[test_ut['class_id']] += 1\n",
    "            else:\n",
    "                res[test_ut['class_id']]['avg_class_test_overall_score'] = float(test_score)\n",
    "                class_counter[test_ut['class_id']] = 1\n",
    "\n",
    "    #compute average score from scores sum and tests number\n",
    "    for class_id, class_res in res.items():\n",
    "            if 'avg_class_test_overall_score' in class_res:\n",
    "                class_res['avg_class_test_overall_score'] /= class_counter[class_id]\n",
    "                \n",
    "    #add every class from classes to ouput dataset (with empty fields)\n",
    "    if show_all_classes:\n",
    "        for class_id, cl in classes.items():\n",
    "            if class_id not in res:\n",
    "                res[class_id] = {\n",
    "                    'class_id': class_id,\n",
    "                    'class_name': cl['name'],\n",
    "                    'teaching_hours': cl['teaching_hours']\n",
    "                }\n",
    "    return res\n",
    "\n",
    "tests_av = get_test_average(tests_ut, tests, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Please save and store these two datasets produced in the 2 earlier tasks in the catalogue from which you retrieved data for calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(data, filename, fieldnames):\n",
    "    with open(filename, 'w') as res_file:\n",
    "        writer = csv.DictWriter(res_file, fieldnames=fieldnames, delimiter=';')\n",
    "        writer.writeheader()\n",
    "        for x in sorted(data, key = lambda x: int(x)):\n",
    "            writer.writerow(data[x])\n",
    "\n",
    "fieldnames_ut = [ 'class_id', 'class_name', 'teaching_hours', 'test_id',\n",
    "                'test_created_at', 'test_authorized_at', 'test_level', 'class_test_number']\n",
    "\n",
    "fieldnames_av = ['class_id', 'class_name', 'teaching_hours', 'test_created_at',\n",
    "                        'test_authorized_at', 'avg_class_test_overall_score']\n",
    "\n",
    "save_dataset(tests_ut, 'results/test_utilization.csv', fieldnames_ut)  \n",
    "save_dataset(tests_av, 'results/test_average_scores.csv', fieldnames_av)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Please prepare a script which allow you to load the earlier prepared datasets to\n",
    "tables in a database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates table for classes\n",
    "CREATE_CLASS_TABLE = (\n",
    "    'CREATE TABLE CLASS ('\n",
    "        'id INTEGER PRIMARY KEY, '\n",
    "        'institution_id INTEGER NOT NULL, '\n",
    "        'owner_id VARCHAR(30), '\n",
    "        'name VARCHAR(50),'\n",
    "        'created_at DATE NOT NULL, '\n",
    "        'updated_at DATE, '\n",
    "        'teaching_hours VARCHAR(10), '\n",
    "        'latest_test_time VARCHAR(30),'\n",
    "        'has_student_with_scored_test VARCHAR(10));')\n",
    "\n",
    "# Creates table for tests' levels\n",
    "CREATE_TEST_LEVEL_TABLE = (\n",
    "    'CREATE TABLE TEST_LEVEL ('\n",
    "        'id INTEGER PRIMARY KEY, '\n",
    "        'name VARCHAR(10), ' \n",
    "        'displayName VARCHAR(10), '\n",
    "        'created_at DATE NOT NULL, '\n",
    "        'updated_at DATE); ')\n",
    "\n",
    "# Creates table for tests\n",
    "CREATE_TEST_TABLE = (\n",
    "    'CREATE TABLE TEST ( '\n",
    "        'id INTEGER PRIMARY KEY, '\n",
    "        'student_id INTEGER NOT NULL, '\n",
    "        'class_id INTEGER NOT NULL, '\n",
    "        'created_at DATE NOT NULL, '\n",
    "        'updated_at DATE, '\n",
    "        'last_event_time DATE, '\n",
    "        'overall_score FLOAT, '\n",
    "        'test_status VARCHAR(30), '\n",
    "        'institution_id VARCHAR(10), '\n",
    "        'authorized_at DATE, '\n",
    "        'confidence_level, '\n",
    "        'speaking_score FLOAT, '\n",
    "        'writing_score FLOAT, '\n",
    "        'reading_score FLOAT, '\n",
    "        'listening_score FLOAT, '\n",
    "        'test_level_id INTEGER NOT NULL, '\n",
    "        'licence_id INTEGER, '\n",
    "        'FOREIGN KEY(class_id) REFERENCES CLASS(id), '\n",
    "        'FOREIGN KEY(test_level_id) REFERENCES TEST_LEVEL(id)); ')\n",
    "\n",
    "# Creates test_utilization table in database\n",
    "TASK_3 = (\n",
    "    'CREATE TABLE TEST_UT AS '\n",
    "    'SELECT '\n",
    "    't.class_id AS class_id, '\n",
    "    'c.name AS class_name, '\n",
    "    'c.teaching_hours, '\n",
    "    't.id AS test_id, '\n",
    "    't.created_at AS test_created_at, '\n",
    "    't.authorized_at AS test_authorized_at, '\n",
    "    'tl.name AS test_level, '\n",
    "    '(SELECT COUNT(*) FROM TEST t2 WHERE t2.authorized_at != \"\" AND t2.id <= t.id AND t2.class_id = t.class_id) AS class_test_number '\n",
    "    'FROM TEST t '\n",
    "    'JOIN CLASS c ON t.class_id = c.id '\n",
    "    'JOIN TEST_LEVEL tl ON t.test_level_id = tl.id '\n",
    "    'WHERE t.authorized_at != \"\"'\n",
    "    'ORDER BY t.id;')\n",
    "\n",
    "# Creates test_average_scores table in database\n",
    "TASK_4 = (\n",
    "    'CREATE TABLE TEST_AVG AS '\n",
    "    'SELECT '\n",
    "    't.class_id, '\n",
    "    'c.name AS class_name, '\n",
    "    'c.teaching_hours, '\n",
    "    't.created_at AS test_created_at, '\n",
    "    't.authorized_at AS test_authorized_at, '\n",
    "    'AVG(t.overall_score) as avg_class_test_overall_score '\n",
    "    'FROM TEST t '\n",
    "    'JOIN CLASS c ON t.class_id = c.id '\n",
    "    'WHERE t.authorized_at != \"\" AND t.test_status = \"SCORING_SCORED\" '\n",
    "    'GROUP BY t.class_id;')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks solved with sqlite3 in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "\n",
    "\n",
    "class EducationDataset:\n",
    "    def __init__(self, db_name, test_path, class_path, test_level_path):\n",
    "        self.db = sql.connect(db_name)\n",
    "        self.cursor = self.db.cursor()\n",
    "        # create tables\n",
    "        self.cursor.execute(CREATE_CLASS_TABLE)\n",
    "        self.cursor.execute(CREATE_TEST_LEVEL_TABLE)\n",
    "        self.cursor.execute(CREATE_TEST_TABLE)\n",
    "        # insert values into tables\n",
    "        self.load_file(class_path, 'CLASS', 9, self.convert_dates)\n",
    "        self.load_file(test_level_path, 'TEST_LEVEL', 5, self.convert_dates)\n",
    "        self.load_file(test_path, 'TEST', 17, self.convert_dates, self.convert_test)\n",
    "        self.db.commit()\n",
    "    \n",
    "    def convert_dates(self, row):\n",
    "        if row['updated_at'] != '':\n",
    "            row['updated_at'] = datetime.strftime(datetime.strptime(row['updated_at'], '%d.%m.%y %H:%M'), '%Y-%m-%d %H:%M:%S')\n",
    "        if row['created_at'] != '':\n",
    "            row['created_at'] = datetime.strftime(datetime.strptime(row['created_at'], '%d.%m.%y %H:%M'), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    def convert_test(self, row):\n",
    "        if row['authorized_at'] != '':\n",
    "            row['authorized_at'] = datetime.strftime(datetime.strptime(row['authorized_at'], '%d.%m.%y %H:%M'), '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    def load_file(self, path, table_name, columns_no, *f_convert):\n",
    "        \"\"\"Load file to table table_name in database\n",
    "\n",
    "        Keyword arguments:\n",
    "        path -- path f file which contains data to load \n",
    "        table_name -- name of table\n",
    "        columns_no -- number of columns in the file\n",
    "        *f_convert -- functions that convert the row so that it can be inserted into database\n",
    "        \"\"\"\n",
    "\n",
    "        with open(path, 'r') as csvfile:\n",
    "            reader = csv.DictReader(csvfile, delimiter=';')\n",
    "            row_pat = ''.join(['?, ' for x in range(columns_no)])[:-2]\n",
    "            for row in reader:\n",
    "                for f in f_convert:\n",
    "                    f(row)\n",
    "                self.cursor.execute('INSERT OR IGNORE INTO ' + \n",
    "                                    table_name + ' VALUES (' + \n",
    "                                    row_pat + ')', list(row.values()))\n",
    "\n",
    "    def do_task(self, task, columns_no):\n",
    "        output_format = ''.join(['{} ' for x in range(columns_no)])\n",
    "        res = self.cursor.execute(task).fetchall()\n",
    "        for r in res:\n",
    "            print(output_format.format(*r).replace('\\n', ''))\n",
    "            \n",
    "ed = EducationDataset(\"ed\", 'input_data/test.csv', 'input_data/class.csv', 'input_data/test_level.csv')\n",
    "ed.do_task(TASK_3, 8)\n",
    "ed.do_task(TASK_4, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
